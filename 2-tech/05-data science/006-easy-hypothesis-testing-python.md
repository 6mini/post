---
title: '가설 검정(Hypothesis Testing)이란?: 파이썬(Python) 예제를 통한 쉬운 이해'
description: "가설 검정(Hypothesis Testing)의 기본 개념과 중요 용어를 쉽게 이해할 수 있도록 설명하고, 파이썬 예제를 통해 실제로 어떻게 가설을 검정하는지 단계별로 알아보는 아티클이다. 귀무 가설, 대립 가설, 유의 수준, p-값 등 가설 검정에 필요한 기본 용어를 명확하게 설명하고, 실제 동전 던지기 실험을 통해 이러한 개념들이 어떻게 적용되는지 보여준다. 이 글은 데이터 과학, 통계학, 또는 연구에서 가설 검정의 기본을 이해하고자 하는 초보자에게 이상적이다."
date: '2024-02-28'
tags: [통계(Statistics), 데이터 분석(Data Analysis), 파이썬(Python), 가설 검정(Hypothesis Testing), 이항 검정(Binomial Test), p-값(p-value), 유의 수준(Significance Level), 귀무 가설(Null Hypothesis), 대립 가설(Alternative Hypothesis), 표본 평균의 표준 오차(Standard Error of the Sample Mean)]
---

# 1. 가설 검정(hypothesis test)이란?

![가설 검정(hypothesis test)](https://user-images.githubusercontent.com/79494088/144995857-499359b0-4588-43a4-8b16-c30fc44d4324.png)

가설 검정(Hypothesis Testing)은 통계학에서 중요한 개념으로, 특정 가설의 타당성을 평가하기 위해 사용하는 방법이다. 관측된 데이터를 바탕으로 통계적 추론을 이용해, 특정 가설이 얼마나 타당한지 결정한다. 가설 검정의 목적은 데이터를 통해 추론을 하고, 모집단에 대해 결정을 내리는 것이다. 간단히 말해, "이것은 사실일까?"라고 생각하는 것에 대해, 수집한 데이터를 이용해 "정말 그럴까?"를 확인하는 과정이다.

## 1.1 가설 검정의 기본 용어

- **귀무 가설 (Null Hypothesis, $H_0$)**: 통계적 검정을 위해 기본적으로 참으로 가정하는 가설이다. 보통 변화, 차이, 효과가 없다는 내용을 담고 있다. 예를 들어, '두 집단 간의 평균 차이가 없다'는 가설이 이에 해당한다.
- **대립 가설 (Alternative Hypothesis, $H_a$ 또는 $H_1$**): 증명하고자 하는 가설로, 귀무 가설과 반대되는 주장이다. 예를 들어, '두 집단 간에 평균 차이가 있다'는 가설이다.
- **유의 수준 (Significance Level, $\alpha$)**: 귀무 가설을 잘못 기각할 확률의 최대 허용치이다. 흔히 사용되는 유의 수준은 0.05(5%)이다.
- **p-값 (p-value)**: 관측된 데이터가 귀무 가설을 지지하는 정도를 나타내는 확률이다. p-값이 유의 수준보다 작으면 귀무 가설을 기각한다.
- **제1종 오류 (Type I Error)**: 귀무 가설이 참일 때, 이를 잘못 기각하는 오류이다.
- **제2종 오류 (Type II Error)**: 대립 가설이 참일 때, 귀무 가설을 잘못 채택하는 오류이다.

처음 본다면 헷갈리는 점이 굉장히 많을 것이다. 나중에 천천히 알아보고, 지속적으로 눈에 담다보면 어느순간 이해를 할 수 있을 것이니, 일단 이런 것들이 있구나라는 것만 알고 넘어가자.

# 2. 가설 검정의 단계

세상에서 제일 간단한 예제를 통해 가설 검정의 단계를 찍먹해보자.

## 2.1 파이썬 코드를 이용한 예시 및 상황 설정

일단 개념을 적용하기전, 파이썬을 통해 간단한 실험을 진행해본다. 동전을 무작위로 던져서 앞면이 나오는지 뒷면이 나오는지 확인하는 실험을 한다고 가정한다.

```py
# 필요 라이브러리 호출
import numpy as np
import pandas as pd

# 랜덤 시드 설정: 랜덤 시드란 랜덤한 값을 생성할 때 사용하는 기준값으로, 같은 랜덤 시드를 사용하면 같은 랜덤값을 얻을 수 있다.
np.random.seed(1111) 

# 동전 던지기 실험
# n = 1: 1번 던지기, p = 0.5: 앞면이 나올 확률 50%, size = 10: 10번 던지기
df = pd.DataFrame({'coinflips': np.random.binomial(n = 1, p = 0.5, size = 10)})

# 결과 확인
df.hist()
```

![10번의 동전 던지기의 결과 히스토그램](https://images.velog.io/images/6mini/post/91b29727-3f0a-41cb-aa68-f3a31cd33954/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202021-07-15%2009.40.39.png)

파이썬의 판다스(Pandas) 라이브러리로, 0과 1을 포함하는 `coinflips`라는 이름의 열(column)을 가진 데이터프레임(DataFrame)을 생성한다. 여기서 `np.random.binomial(n = 1, p = 0.5, size = 10)`은 넘파이(NumPy) 라이브러리를 사용하여 이항 분포(binomial distribution)에서 무작위 샘플을 생성하는 함수다.

- `n=1`: 각 시행(trial)에서의 성공 횟수를 의미한다. 이 경우에는 동전을 한 번 던지는 것과 같으므로 1이다.
- `p=0.5`: 각 시행에서 성공할 확률(probability)을 의미한다. 동전 던지기에서 앞면(또는 뒷면)이 나올 확률이 0.5이다.
- `size=10`: 샘플의 크기(size)를 의미한다. 즉, 동전을 10번 던지는 것과 같다.

동전을 10번 던져서 나온 결과(앞면 또는 뒷면)를 나타내는 0과 1의 배열을 생성하고, 이 배열을 `coinflips`라는 열 이름으로 가진 데이터프레임에 저장한다. 데이터프레임의 각 행(row)은 동전 던지기의 한 번의 시행 결과를 나타낸다.

히스토그램을 통해 결과를 확인해보면, 동전을 10번 던졌을 때 앞면은 7번, 뒷면은 3번 나왔다는 것을 알 수 있다. 그렇다면 앞면이 나올 확률은 70%이고, 뒷면이 나올 확률은 30%라고 할 수 있을까? 이것이 바로 가설 검정의 시작이다.

### 2.1.1 실험 결과 확장

실험의 신뢰도를 확인하기 위해, 동전을 100번과 1000번 던지는 시나리오를 추가로 진행한다. 이를 통해 더 많은 데이터를 수집함으로써, 결과의 신뢰성이 샘플 크기에 어떻게 영향을 받는지 관찰할 수 있다.

```python
# 동전을 100번 던지기
pd.DataFrame(np.random.binomial(n = 1, p = 0.5, size = 100)).hist();

# 동전을 1000번 던지기
pd.DataFrame(np.random.binomial(n = 1, p = 0.5, size = 1000)).hist();
```

![](https://images.velog.io/images/6mini/post/3e32084c-3e6c-4625-9057-f392987261d0/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202021-07-15%2009.41.30.png)

동전을 더 많이 던질수록 앞면과 뒷면이 나올 확률이 거의 동일하다는 이론적 가정에 더 가까워지는 경향을 관찰할 수 있다. 이를 통해 '샘플 크기의 중요성'을 실제로 확인할 수 있다. 샘플 크기가 클수록 관찰한 결과는 모집단의 실제 특성을 더 잘 반영하게 된다.

### 2.1.2 표본 평균의 표준 오차(Standard Error of the Sample Mean)

동전을 더 많이 던질수록, 즉 표본의 크기가 클수록 결과의 신뢰성이 증가하는 걸 확인할 수 있었고 이 현상은 표본 평균의 표준 오차 공식을 통해 수학적으로 설명할 수 있다.

![표본 평균의 표준 오차(Standard Error of the Sample Mean)](https://user-images.githubusercontent.com/79494088/144996198-9f0d54ee-3032-48d1-89ab-19037033c24d.png)

표본 평균의 표준 오차(Standard Error of the Sample Mean, SE)는 표본 평균이 모집단 평균에서 얼마나 분산될 수 있는지를 측정하는 지표로, 표본 평균의 정확도와 신뢰성을 나타낸다. 표준 오차는 다음 공식으로 계산된다:

$ SE = \frac{S}{\sqrt{N}} $

여기서,

- $S$ (우측) = 표본의 표준편차(Sample Standard Deviation)
- $N$ = 표본의 수(Sample Size): 표본에서 관측된 값의 수
	- **결론: 표본의 수가 더욱 많아질수록, 추측은 더 정확해지고(평균) 높은 신뢰도를 바탕으로 모집단에 대해 예측 할 수 있도록 한다.**

동전을 더 많이 던질수록(표본의 크기를 늘릴수록), 앞면이 나올 확률의 평균은 실제 확률인 50%에 더 가까워진다. 이는 표본 평균의 변동성이 줄어들고, 결과적으로 추정이 더 정확해지며 높은 신뢰도를 가지게 됨을 의미한다.

이제 이 예시를 통해 가설 검정의 단계를 살펴보자.

## 2.2 가설 설정

가설 검정의 첫 단계는 연구 질문에 기반하여 귀무 가설($H_0$)과 대립 가설($H_a$ 또는 $H_1$)을 설정하는 것이다. 이 두 가설은 서로 배타적이며, 함께 연구 질문의 범위를 정의한다.

### 2.2.1 귀무 가설($H_0$)

귀무 가설은 보통 변화, 효과, 차이가 없다는 가정을 설정한다. 증명하고자 하는 가설의 반대 입장을 취하며, 통계적 검정의 기준점으로 사용된다. 예를 들어, 동전 던지기 실험에서 귀무 가설은 "동전은 공정하다(앞면이 나올 확률 = 0.5)"로 설정될 수 있다. 이는 모든 관측이 우연에 의한 것임을 가정한다.

### 2.2.2 대립 가설($H_a$ 또는 $H_1$)

대립 가설은 실제로 증명하고자 하는 가설이다. 이는 귀무 가설과 반대되는 주장을 하며, 보통 변화, 효과, 차이가 있다는 가정을 설정한다. 동전 던지기의 경우, 대립 가설은 "동전은 공정하지 않다(앞면이 나올 확률 ≠ 0.5)"로 설정된다.

## 2.3 유의 수준($\alpha$) 설정

귀무 가설을 잘못 기각할 최대 허용 확률을 의미하며, 직접 설정한다. 유의 수준은 보통 0.05(5%) 또는 0.01(1%)로 설정되며, 이 값은 귀무 가설을 기각하기 위한 증거의 강도를 나타낸다. 유의 수준이 낮을수록 우연히 귀무 가설을 기각할 확률이 낮아지므로, 보다 엄격한 기준을 적용하는 것이다.

```py
alpha = 0.05  # 유의 수준 설정
```

## 2.4 통계적 검정 수행

이 단계에서는 적절한 통계적 검정 방법을 선택하여 실험 또는 관찰 데이터에 적용한다. 선택한 검정 방법은 연구 질문, 데이터의 종류, 가정 등에 따라 달라질 수 있다. 동전 던지기의 경우, 이항 검정(binomial test)이 적합한 방법이다. 이 검정은 동전 던지기와 같이 두 가지 결과만 가능한 시행에서의 결과 분포를 분석한다.

통계적 검정을 수행한 후, p-값(p-value)을 계산한다. p-값은 귀무 가설 하에서 관찰된 결과(또는 더 극단적인 결과)가 발생할 확률을 나타낸다. 이 값은 귀무 가설을 지지하는 정도를 나타내며, 유의 수준과 비교하여 가설을 기각할지 결정하는 기준이 된다.

100번의 동전 던지기 실험을 가정하고, 이항 검정을 수행한다. 동전이 앞면이 나온 횟수를 60번으로 가정한다:

```py
import numpy as np
from scipy.stats import binom_test

# 실험 데이터 설정
n = 100  # 동전 던지기 횟수
x = 60   # 앞면이 나온 횟수

# 이항 검정 수행
p_value = binom_test(x, n, p=0.5, alternative='two-sided')

print(f'p-value: {p_value}')
'''
p-value: 0.05688793364098088
'''
```

`scipy` 라이브러리의 `binom_test` 함수를 사용하여 이항 검정을 수행한다. `alternative='two-sided'` 옵션은 양측 검정을 의미하며, 이는 동전이 공정하지 않다는 것이 앞면이 나올 확률이 더 높거나 낮다는 양방향 가설을 검정한다.

## 2.5 결론 도출

마지막으로 계산된 p-값과 설정한 유의 수준($\alpha$)을 비교하여 귀무 가설을 기각할지 여부를 결정한다.

- p-value ≤ $\alpha$: 귀무 가설을 기각하고, 연구 결과가 통계적으로 유의하다고 결론 지을 수 있다. 이 경우, 대립 가설을 지지하는 것으로 간주되며, 연구 가설이 데이터에 의해 뒷받침된다.
- p-value > $\alpha$: 귀무 가설을 기각할 충분한 증거가 없다고 판단한다. 이 경우, 데이터가 귀무 가설을 뒷받침한다고 결론 내리며, 연구 가설을 지지할 수 없다.

```py
if p_value < alpha:
    print("귀무 가설을 기각한다. 동전은 공정하지 않다.")
else:
    print("귀무 가설을 기각할 충분한 증거가 없다. 동전은 공정할 수 있다.")
'''
귀무 가설을 기각할 충분한 증거가 없다. 동전은 공정할 수 있다.
'''
```

p-값이 `0.05688793364098088`로 계산되었다. 이 결과를 유의 수준과 비교하여 가설 검정의 결론을 도출할 수 있다. 설정한 유의 수준이 0.05(5%)라고 했을 때, p-값은 유의 수준보다 약간 높다.

"귀무 가설을 기각할 충분한 증거가 없다. 동전은 공정할 수 있다."라는 결론을 내리며, 이는 실험 결과가 통계적으로 유의미하게 동전이 공정하지 않다고 말할 수 없다는 것을 의미한다. 즉, 실험에서 관찰된 동전 앞면의 비율이 우연히 발생할 수 있는 범위 내에 있다고 해석할 수 있다. 그럼에도 불구하고, p-값이 유의 수준보다 조금 높다고 해서 바로 대립 가설이 사실이라고 결론내릴 수 없으며, 더 많은 데이터 또는 다른 방법론을 통한 추가적인 검증이 필요할 수 있다.

# 3. 마무리 및 참고

## 3.1 결론

이러한 과정을 통해 데이터를 기반으로 한 통계적 결론을 내릴 수 있으며, 질문에 대한 답을 찾는 데 필요한 과학적 근거를 제공한다. 가설 검정은 연구의 타당성과 신뢰성을 높이는 중요한 도구로, 다양한 분야에서 널리 사용된다.

## 3.2 관련 아티클

- [데이터 사이언스에서의 미분: 기본 개념, 공식 및 경사하강법 이해](fundamentals-of-differentiation-in-data-science)
- [통계학 기초: 기술 통계 vs 추리 통계](/statistics-descriptive-vs-inferential)
- [가설 검정(Hypothesis Testing)이란?: 파이썬(Python) 예제를 통한 쉬운 이해](/easy-hypothesis-testing-python)

## 3.3 참고

- [가설 검정](https://ko.wikipedia.org/wiki/%EA%B0%80%EC%84%A4_%EA%B2%80%EC%A0%95)